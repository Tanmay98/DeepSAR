<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" href="./styles.css">
</head>
<body>
    <h1>DeepSAR: Vessel Detection in SAR Imagery With Noisy Labels</h1>

    <img src="full-arch1.jpg" alt="Trulli" width="1000" height="400">
    <figcaption>
        Our proposed training pipeline. The input SAR image bands are converted to false-color RGB, and then the FPN architecture is used to extract multi-resolution features combined using the Upsampling Stage to create high-resolution 
        128-dimensional pixel-level feature vectors. The extracted features are then used to predict foreground regions using a Foreground-Background (FB) classifier head (class-agnostic detector). Finally, the predicted foreground regions 
        and feature vectors are used to predict the semantic segmentation map using a Semantic Segmentation (SS) head.
    </figcaption>

    <h2>    Abstract</h2>
    <p>
        Unlike traditional optoelectronic satellite imaging, Synthetic Aperture Radar (SAR) allows remote sensing applications to operate under all weather conditions. This makes it uniquely valuable for detecting ships/vessels involved in 
        illegal, unreported, and unregulated (IUU) fishing. While recent work has shown significant improvement in this domain, detecting small objects using noisy point annotations remains an unexplored area. In order to meet the unique challenges 
        of this problem, we propose a progressive training methodology that utilizes two different spatial sampling strategies. Firstly, we use stochastic sampling of background points to reduce the impact of class imbalance and missing labels, and 
        secondly, during the refinement stage, we use hard negative sampling to improve the model. Experimental results on the challenging xView3 dataset show that our method outperforms conventional small object localization methods in a large, noisy 
        dataset of SAR images.

    </p>

    <h2>    Performance</h2>
    <img src="score.JPG" alt="Trullii" width="800" height="150">
    <figcaption>
        Comparison of our approach with state-of-the-art methods for small object localization and generic object localization on the validation split of the xView3 dataset.
        F1<sub>D</sub>: Detection F1, F1<sub>S</sub>: Close-to-Shore Detection F1, F1<sub>V</sub>: Vessel Classification F1, F1<sub>C</sub>: Fishing Classification F1). <br> <sup>[G]</sup> : Generic method not adapted for small objects
    </figcaption>

    <h2>    Visualization</h2>
    
    <div class="row">
        <div class="column">
            <img src="quant_input.png" alt="Trulli" style="width: 100%">
            <figcaption>    Input Scene     </figcaption>
        </div>
        <div class="column">
            <img src="quant_true.png" alt="b" style="width: 100%">
            <figcaption>    Ground Truth    </figcaption>
        </div>
        <div class="column">
            <img src="quant_ours.png" alt="v" style="width: 100%">
            <figcaption>    DeepSAR(Ours)   </figcaption>
        </div>
        <div class="column">
            <img src="quant_farseg_1.png" alt="f" style="width: 100%">
            <figcaption>    FarSeg      </figcaption>
        </div>
        <div class="column">
            <img src="quant_psp_1.png" alt="d" style="width: 100%">
            <figcaption>    PSPNet      </figcaption>
        </div>
        <div class="column">
            <img src="quant_factseg_1.png" alt="r" style="width: 100%">
            <figcaption>    FactSeg     </figcaption>
        </div>

        <!-- <figcaption>
            Maritime object detection from xView3 data. (a) Input SAR} image in pseudo color RGB. (b) Ground truth segmentation map {red: non-vessel, green: fishing vessel, blue: non-fishing vessel}. (c) Foreground-Background and (d) Vessel Class 
            segmentation map predicted by our method.
        </figcaption> -->

    </div>
    <figcaption>
        Qualitative comparison of our approach with other methods for small object localization on the validation split of xView3 dataset. (red: non-vessel, green: fishing vessel, 
        blue: {non-fishing vessel). Red circles represent false detections or misclassifications by the model.
    </figcaption>

    <h2>    Reference</h2>
    <p></p>
</body>
</html>